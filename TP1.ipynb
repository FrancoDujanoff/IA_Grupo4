{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jWUX78DM7n9T"
   },
   "source": [
    "# Temas Tratados en el Trabajo Práctico 1\n",
    "\n",
    "* Diferencia entre Inteligencia e Inteligencia Artificial.\n",
    "\n",
    "* Concepto de omnisciencia, aprendizaje y autonomía.\n",
    "\n",
    "* Definición de Agente y sus características. Clasificación de Agentes según su estructura.\n",
    "\n",
    "* Identificación y categorización del Entorno de Trabajo en tabla REAS.\n",
    "\n",
    "* Caracterización del Entorno de Trabajo.\n",
    "\n",
    "# Anotaciones\n",
    "\n",
    "\"Acordarse de la definición de agente\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios Teóricos\n",
    "\n",
    "1. Defina con sus propias palabras inteligencia natural, inteligencia artificial y agente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La inteligencia natural es la propia generada por la naturaleza en los sere vivos, la cual esta dada por eventos que ocurren en el cerebro. asdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La inteligencia artificial es aquella inteligencia que esta desarrollada completamente dentro de una computadora, y que funciona mediante un algoritmo generado por una persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un agente es alguna cosa que interactua con el entorno, a partir de percepciones que recibe de el"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. ¿Qué es un agente racional?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un agente racional es aquel que elige la accion que supuestamente maximice su medida de rendimiento, basandose en las evidencias aportadas por la secuencia de percepciones y en el conocimiento que el agente mantiene almacenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ¿Un agente es siempre una computadora?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No todos los agentes son desarrollados por computadoras, como un agente es alguien que pecibe su entorno y actua sobre el, un agente si puede ser una computadora, pero tambien puede ser un ser vivo que recibe sentidos y actua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Defina Omnisciencia, Aprendizaje y Autonomía."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Omnisciencia es el conocimiento completo y perfecto sobre el estado actual del entorno y sobre las consecuencias de cada una de las acciones posibles, esto es imposible en entornos reales debido a que existe incertidumbre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprendizaje es el proceso mediante el cual un agente mejora su comportamiento a partir del estudio de experiencias pasadas y predicciones sobre el futuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autonomia es la capacidad de un agente de operar y tomar decisiones sin intervencion humana directa, basandose en sus propias percepciones y conocimientos adquiridos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Defina cada tipo de agente en función de su **estructura** y dé un ejemplo de cada categoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agente Reactivo Simple: funcion con reglas, a una determinada condicion le sigue una determinada accion. No almacena informacion del pasado, sino que responde directamente a las percepciones actuales. Por ejemplo un robot aspiradora basico que gira cuando detecta un obstaculo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agente Reactivo basado en Modelos: mantiene un estado interno que representa informacion sobre el mundo no visible en el momento, usa ese estado y un modelo de como evoluciona el entorno para decidir. Por ejemplo un termostato que predice temperatura usando el modelo fisico, para decidir si prender o apagar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agente basado en Objetivos: ademas del estado, tiene una descripcion de objetivos y elige las acciones que mas lo acercen a los objetivos. Por ejmplo un GPS que planifica la ruta mas corta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agente basado en Utilidad: usa en funcon de utilidad que mide que tan bueno es un estado para el agente, elige acciones que maximizan la utilidad esperada. Por ejemplo un auto autonomo que elige la maniobra mas segura y rapida, considerando todos los aspectos externos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agente que aprende: integra componentes de aprendizaje para mejorar su rendimiento con la experiencia. Por ejemplo un sistema de recomendacion que mejora la sugerencias de productos a un usuario, dependiendo de las compras que haga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Para los siguientes entornos de trabajo indique sus **propiedades**:\n",
    "\n",
    "        a. Una partida de ajedrez. Contexto: una partida de dos jugadores donde cada uno busca realizar los movimientos con la mayor probabilidad de éxito; el punto de vista estará enfocado en la partida como tal. Propiedades: Totalmente observable, puesto que se conoce toda la información; determinista, debido a que ambos jugadores juegan con las jugadas más probables; secuencial, ya que la jugada previa de cada jugador afectará a los movimientos futuros de ambos; estático y acotado, considerando que las jugadas son las más probables; discreto, hay un conjunto finito de movimientos posibles; multiagente.\n",
    "\n",
    "        b. Un partido de baloncesto. Contexto: un partido de dos equipos de jugadores; el punto de vista estará enfocado en la partida en general. Propiedades: Totalmente observable; estocástico, ya que los movimientos pueden ser inprevisibles; secuencial, ya que, analizando la partida como tal y no los movimientos individuales de cada jugador, el movimiento de cada uno afectará el juego en general; dinámico; contínuo; multiagente.\n",
    "\n",
    "        c. El juego Pacman. Contexto: un jugador jugando al juego de pacman; el punto de vista estará enfocado en la partida, no los movimientos individuales y el jugador realizará los movimientos con mayor probabilidad de éxito. Propiedades: Totalmente observable; determinista, puesto que los movimientos de pacman y los fantasmas son previamente establecidos; secuencial, porque los movimientos de pacman no afectan el comportamiento de los fantasmas; discreto, por tener respuestas acotadas; multiagente.\n",
    "\n",
    "        d. El truco. Contexto: una partida de dos jugadores donde la estrategia de cada jugador dependerá de la jugada previa del otro jugador, punto de vista enfocado en un solo jugador a medida que juega. Propiedades: parcialmente observable, pues habrá un agente que no es observable; estocástico, porque depende de los movimientos del otro jugador; secuencial, ya que dependerá de las jugadas anteriores (por ejemplo, si en la primer ronda empardan, en la segunda deberá jugar la carta de mayor valor a pesar de que en un principio la estrategia sería dejarla para el final); estático; dinámico; discreto, puesto que los movimientos son acotados; multiagente.  \n",
    "\n",
    "        e. Las damas. Contexto: juego de tablero de dos jugadores, donde el objetivo es capturar las fichas del rival o bloquear sus movimientos; se analiza la partida como un todo. Propiedades: Totalmente observable, se ve todo el tablero y las fichas; determinista, debido a que ambos jugadores juegan con las jugadas más probables; secuencial, cada jugada modifica el estado y afecta el futuro de la partida; estático, el tablero no cambia mientras un jugador decide; discreto, hay un número finito de movimientos posibles en cada turno; multiagente.\n",
    "\n",
    "        f. El juego tres en raya. Contexto: juego simple de tablero de dos jugadores que buscan colocar tres marcas iguales en línea; el análisis es de la partida completa. Propiedades: Totalmente observable, el tablero y todas las jugadas son visibles; determinista,  debido a que ambos jugadores juegan con las jugadas más probables; secuencial, cada movimiento cambia el tablero y condiciona el siguiente; estático, no cambia el entorno mientras se decide; discreto, hay un conjunto finito de movimientos posibles; multiagente, participan dos jugadores.\n",
    "\n",
    "        g. Un jugador de Pokémon Go. Contexto: jugador que recorre el mundo real buscando capturar Pokémon; el análisis es desde el punto de vista del jugador. Propiedades: parcialmente observable, no se sabe con certeza qué Pokémon aparecerán ni dónde; estocástico, la aparición de Pokémon y eventos depende de probabilidades; secuencial,las decisiones del jugador (rutas, capturas) afectan oportunidades futuras; dinámico, el entorno cambia en tiempo real (ubicación, clima, eventos); continuo: el espacio de movimiento del jugador es continuo (mundo real con GPS); multiagente: interactúa con otros jugadores en gimnasios, incursiones o intercambios.\n",
    "\n",
    "        h. Un robot explorador autónomo de Marte. Contexto: robot que se desplaza por la superficie marciana para recolectar datos, tomar imágenes y realizar análisis, tomando decisiones sin control humano constante. Propiedades: Parcialmente observable, no puede conocer todo el entorno a la vez, solo lo que captan sus sensores; estocástico, el terreno y las condiciones (polvo, clima) pueden ser impredecibles, así como fallos en los sensores; secuencial, cada decisión afecta las siguientes rutas y acciones; dinámico, el entorno puede cambiar mientras decide (tormentas de polvo, luz solar variable); continuo, el espacio y el tiempo de movimiento no se conocen totalmetne; agente único, actúa de forma autónoma, aunque pueda recibir instrucciones desde la Tierra.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Elabore una tabla REAS para los siguientes entornos de trabajo:\n",
    "\n",
    "        a. Crucigrama.\n",
    "\n",
    "        b. Taxi circulando.\n",
    "\n",
    "        c. Robot clasificador de piezas.\n",
    "\n",
    "        Agente: {}\n",
    "        Medidas de Rendimiento: {}\n",
    "        Entorno: {}\n",
    "        Actuadores: {}\n",
    "        Sensores: {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios Prácticos\n",
    "\n",
    "8. La Hormiga de Langton es un agente capaz de modificar el estado de la casilla en la que se encuentra para colorearla o bien de blanco o de negro. Al comenzar, la ubicación de la hormiga es una casilla aleatoria y mira hacia una de las cuatro casillas adyacentes. Si...\n",
    "\n",
    "* ... la casilla sobre la que está es blanca, cambia el color del cuadrado, gira noventa grados a la derecha y avanza un cuadrado.\n",
    "\n",
    "* ... la casilla sobre la que está es negra, cambia el color del cuadrado, gira noventa grados a la izquierda y avanza un cuadrado.\n",
    "\n",
    "    Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
    "\n",
    "    ¿Observa que se repite algún patrón? De ser así, ¿a partir de qué iteración?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este juego si tiene un patron que se repite, luego de un numero grande de repeticiones, en donde sale de la zona de caos y comienza a formar una linea \"recta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla REAS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agente: Hormiga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rendimiento: Moverse segun las reglas indicadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entorno: Rejilla de celdas bidimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actuadores: Avanzar. Girar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensores: Sensor de color. Sensor de orientacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propiedades del entorno:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Totalmente observable, Determinista, Secuencial, Estatico, Discreto y Agente Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle\n",
    "import sys\n",
    "import math\n",
    "from win32api import GetSystemMetrics\n",
    "from easygui import multenterbox, msgbox\n",
    "\n",
    "def langtonAnt():\n",
    "    # Pedir datos\n",
    "    msg = (\"Por favor, introduzca los datos\"\n",
    "           \"\\nNota 1: La posición x, y = (0, 0) es el centro de la ventana.\"\n",
    "           \"\\nNota 2: La hormiga sigue un camino aparentemente azaroso hasta los 10.000 pasos.\")\n",
    "    title = \"La hormiga de Langton\"\n",
    "    fieldNames = [\"Número de movimientos:\", \"Posición inicial x:\", \"Posición inicial y:\", \"Tamaño <<n>> de la grilla:\"]\n",
    "    fieldValues = multenterbox(msg, title, fieldNames)\n",
    "    if fieldValues is None:\n",
    "        sys.exit(0)\n",
    "\n",
    "    # Validación\n",
    "    while True:\n",
    "        errorMsg = \"\"\n",
    "        for i, name in enumerate(fieldNames):\n",
    "            if fieldValues[i].strip() == \"\":\n",
    "                errorMsg += \"{} es un campo requerido.\\n\\n\".format(name)\n",
    "        if errorMsg == \"\":\n",
    "            break\n",
    "        fieldValues = multenterbox(errorMsg, title, fieldNames, fieldValues)\n",
    "        if fieldValues is None:\n",
    "            break\n",
    "\n",
    "    # Configuración ventana\n",
    "    widht = GetSystemMetrics(0)\n",
    "    height = GetSystemMetrics(1)\n",
    "    wn = turtle.Screen()\n",
    "    wn.title(\"La Hormiga de Langton - Rápida\")\n",
    "    wn.bgcolor(\"white\")\n",
    "    wn.screensize(widht, height)\n",
    "    wn.tracer(0, 0)  # <-- Desactivar animación\n",
    "\n",
    "    border((int(fieldValues[3])+10))\n",
    "\n",
    "    # Texto de movimientos\n",
    "    text = turtle.Turtle()\n",
    "    text.hideturtle()\n",
    "    text.color(\"red\")\n",
    "    text.penup()\n",
    "    text.goto(0, 300)\n",
    "\n",
    "    # Diccionario de celdas\n",
    "    maps = {}\n",
    "\n",
    "    # Configuración de la hormiga\n",
    "    ant = turtle.Turtle()\n",
    "    ant.shape(\"square\")\n",
    "    ant.shapesize(0.5)\n",
    "    ant.penup()\n",
    "    ant.goto(int(fieldValues[1]), int(fieldValues[2]))\n",
    "    ant.speed(0)\n",
    "    pos = coordinate(ant)\n",
    "\n",
    "    # Variables\n",
    "    cont = 0\n",
    "    hit = False\n",
    "    step = 10\n",
    "\n",
    "    # Bucle principal\n",
    "    while cont <= int(fieldValues[0])-1 and not hit:\n",
    "        if pos not in maps or maps[pos] == \"white\":\n",
    "            ant.fillcolor(\"black\")\n",
    "            ant.stamp()\n",
    "            maps[pos] = \"black\"\n",
    "            ant.right(90)\n",
    "        else:\n",
    "            ant.fillcolor(\"white\")\n",
    "            ant.stamp()\n",
    "            maps[pos] = \"white\"\n",
    "            ant.left(90)\n",
    "\n",
    "        ant.forward(step)\n",
    "        pos = coordinate(ant)\n",
    "        cont += 1\n",
    "\n",
    "        # Verificar bordes\n",
    "        if round(abs(ant.xcor())) > (int(fieldValues[3]) / 2) - 1 or \\\n",
    "           round(abs(ant.ycor())) > (int(fieldValues[3]) / 2) - 1:\n",
    "            hit = True\n",
    "            msgbox(\"La hormiga chocó con los bordes. Use una grilla más grande.\")\n",
    "\n",
    "        # Actualizar solo cada 100 pasos para más velocidad\n",
    "        if cont % 100 == 0 or hit:\n",
    "            text.clear()\n",
    "            text.write(f\"Movimientos: {cont}\", align=\"center\", font=(\"Courier\", 24, \"normal\"))\n",
    "            wn.update()\n",
    "\n",
    "    wn.update()\n",
    "    wn.mainloop()\n",
    "\n",
    "def coordinate(ant):\n",
    "    return (round(ant.xcor()), round(ant.ycor()))\n",
    "\n",
    "def border(n):\n",
    "    b = turtle.Turtle()\n",
    "    b.hideturtle()\n",
    "    b.penup()\n",
    "    b.goto(n/2, 0)\n",
    "    b.pendown()\n",
    "    b.left(90)\n",
    "    for _ in range(4):\n",
    "        b.forward(n)\n",
    "        b.left(90)\n",
    "\n",
    "langtonAnt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. El Juego de la Vida de Conway consiste en un tablero donde cada casilla representa una célula, de manera que a cada célula le rodean 8 vecinas. Las células tienen dos estados: están *vivas* o *muertas*. En cada iteración, el estado de todas las células se tiene en cuenta para calcular el estado siguiente en simultáneo de acuerdo a las siguientes acciones:\n",
    "\n",
    "* Nacer: Si una célula muerta tiene exactamente 3 células vecinas vivas, dicha célula pasa a estar viva.\n",
    "\n",
    "* Morir: Una célula viva puede morir sobrepoblación cuando tiene más de tres vecinos alrededor o por aislamiento si tiene solo un vecino o ninguno.\n",
    "\n",
    "* Vivir: una célula se mantiene viva si tiene 2 o 3 vecinos a su alrededor.\n",
    "\n",
    "    Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
    "\n",
    "REAS (por célula-agente)\n",
    "\n",
    "Rendimiento: Persistencia de patrones locales (p. ej., “seguir vivo si hay 2–3 vecinas” o “nacer si hay 3”).\n",
    "(Opcional) Objetivos emergentes: maximizar supervivencia local o estabilidad del patrón. Para lo que fue creado el código cumple con las expectativas\n",
    "\n",
    "Entorno: Las 8 celdas vecinas inmediatas (vecindad de Moore) y su estado actual en cada tick.\n",
    "\n",
    "Actuadores: Cambiar su propio estado en el próximo tick.\n",
    "\n",
    "Sensores: Contar vecinas vivas (lectura de estados inmediatos).\n",
    "\n",
    "Propiedades del entorno (desde la perspectiva de cada célula)\n",
    "\n",
    "Observabilidad: Parcial-local (solo percibe vecinas inmediatas; globalmente, el sistema es observable si miramos toda la grilla).\n",
    "\n",
    "Determinismo: Determinista (su próxima acción/estado depende únicamente del recuento local actual).\n",
    "\n",
    "Episódico vs. Secuencial: Secuencial (la historia importa a través del estado previo).\n",
    "\n",
    "Estático vs. Dinámico: Dinámico por ticks (las vecinas pueden cambiar en cada paso).\n",
    "\n",
    "Discreto vs. Continuo: Discreto.\n",
    "\n",
    "Individual vs. Multiagente: Multiagente (muchas células actuando en paralelo con reglas locales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "from typing import Tuple, Set\n",
    "\n",
    "# -----------------------------\n",
    "# Parámetros básicos\n",
    "# -----------------------------\n",
    "WIDTH, HEIGHT = 800, 800     # ventana\n",
    "NCX, NCY = 80, 80            # celdas en X e Y\n",
    "FPS = 60                     # tope de refresco\n",
    "BG = (25, 25, 25)            # color fondo\n",
    "GRID_COLOR = (80, 80, 80)\n",
    "ALIVE_COLOR = (240, 240, 240)\n",
    "\n",
    "# -----------------------------\n",
    "# Inicialización\n",
    "# -----------------------------\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Juego de la Vida - Interactivo\")\n",
    "clock = pygame.time.Clock()\n",
    "font = pygame.font.SysFont(\"consolas\", 16)\n",
    "\n",
    "dimCW = WIDTH / NCX\n",
    "dimCH = HEIGHT / NCY\n",
    "\n",
    "# Estado: 1 viva, 0 muerta\n",
    "gameState = np.zeros((NCX, NCY), dtype=np.uint8)\n",
    "\n",
    "# Control ejecución\n",
    "paused = True\n",
    "toroidal = True\n",
    "random_density = 0.15  # densidad para aleatorizar\n",
    "step_delay = 0.0       # retardo opcional por paso\n",
    "\n",
    "# -----------------------------\n",
    "# Utilidades: reglas B/S\n",
    "# -----------------------------\n",
    "def parse_rulestring(rs: str) -> Tuple[Set[int], Set[int]]:\n",
    "    \"\"\"\n",
    "    rs: 'B3/S23', 'B36/S23', 'B2/S', etc.\n",
    "    Devuelve (born_set, survive_set)\n",
    "    \"\"\"\n",
    "    rs = rs.upper().replace(\" \", \"\")\n",
    "    if \"/\" not in rs:\n",
    "        raise ValueError(\"Regla inválida, usa formato B*/S* (ej. B3/S23)\")\n",
    "    b, s = rs.split(\"/\")\n",
    "    if not (b.startswith(\"B\") and s.startswith(\"S\")):\n",
    "        raise ValueError(\"Regla inválida, debe comenzar con B.../S...\")\n",
    "    born = {int(c) for c in b[1:] if c.isdigit()}\n",
    "    surv = {int(c) for c in s[1:] if c.isdigit()}\n",
    "    return born, surv\n",
    "\n",
    "# Reglas comunes para ciclar con F\n",
    "COMMON_RULES = [\n",
    "    (\"Conway\",       \"B3/S23\"),\n",
    "    (\"HighLife\",     \"B36/S23\"),\n",
    "    (\"Seeds\",        \"B2/S\"),\n",
    "    (\"Life w/out D\", \"B3/S012345678\"),\n",
    "    (\"Day&Night\",    \"B3678/S34678\"),\n",
    "    (\"Maze\",         \"B3/S12345\"),\n",
    "]\n",
    "\n",
    "rule_index = 0\n",
    "rule_name, rule_string = COMMON_RULES[rule_index]\n",
    "BORN, SURV = parse_rulestring(rule_string)\n",
    "\n",
    "def apply_rules(alive: int, neighbors: int) -> int:\n",
    "    \"\"\"Devuelve 1/0 según reglas B/S actuales.\"\"\"\n",
    "    if alive:\n",
    "        return 1 if neighbors in SURV else 0\n",
    "    else:\n",
    "        return 1 if neighbors in BORN else 0\n",
    "\n",
    "# -----------------------------\n",
    "# Vecindad\n",
    "# -----------------------------\n",
    "NB_OFFSETS = [(-1,-1),(0,-1),(1,-1),\n",
    "              (-1, 0),        (1, 0),\n",
    "              (-1, 1),(0, 1),(1, 1)]\n",
    "\n",
    "def count_neighbors(state: np.ndarray, x: int, y: int, wrap: bool) -> int:\n",
    "    n = 0\n",
    "    for dx, dy in NB_OFFSETS:\n",
    "        nx, ny = x + dx, y + dy\n",
    "        if wrap:\n",
    "            nx %= NCX\n",
    "            ny %= NCY\n",
    "            n += state[nx, ny]\n",
    "        else:\n",
    "            if 0 <= nx < NCX and 0 <= ny < NCY:\n",
    "                n += state[nx, ny]\n",
    "    return n\n",
    "\n",
    "# -----------------------------\n",
    "# Patrones predefinidos\n",
    "# -----------------------------\n",
    "def pattern_glider():\n",
    "    # Forma estándar (orientación NE)\n",
    "    return [(0,2),(1,0),(1,2),(2,1),(2,2)]\n",
    "\n",
    "def pattern_lwss():\n",
    "    # Lightweight spaceship 5x4\n",
    "    return [(0,1),(0,3),(1,0),(2,0),(3,0),(4,0),(4,3),(1,4),(4,1),(4,2)]\n",
    "\n",
    "def pattern_pulsar():\n",
    "    # Pulsar (periodo 3), centrado en 13x13 aprox\n",
    "    pts = []\n",
    "    offs = [\n",
    "        (2,0),(3,0),(4,0),(8,0),(9,0),(10,0),\n",
    "        (0,2),(5,2),(7,2),(12,2),\n",
    "        (0,3),(5,3),(7,3),(12,3),\n",
    "        (0,4),(5,4),(7,4),(12,4),\n",
    "        (2,5),(3,5),(4,5),(8,5),(9,5),(10,5),\n",
    "\n",
    "        (2,7),(3,7),(4,7),(8,7),(9,7),(10,7),\n",
    "        (0,8),(5,8),(7,8),(12,8),\n",
    "        (0,9),(5,9),(7,9),(12,9),\n",
    "        (0,10),(5,10),(7,10),(12,10),\n",
    "        (2,12),(3,12),(4,12),(8,12),(9,12),(10,12),\n",
    "    ]\n",
    "    return offs\n",
    "\n",
    "def pattern_gosper_glider_gun():\n",
    "    # Gunn de Gosper (36x9 aprox)\n",
    "    pts = [\n",
    "        (1,5),(2,5),(1,6),(2,6),\n",
    "        (13,3),(14,3),(12,4),(16,4),(11,5),(17,5),(11,6),(15,6),(13,7),(14,7),(12,8),(16,8),\n",
    "        (21,5),(22,5),(21,6),(22,6),(23,4),(23,7),\n",
    "        (25,3),(25,4),(25,7),(25,8),\n",
    "        (35,5),(36,5),(35,6),(36,6)\n",
    "    ]\n",
    "    return pts\n",
    "\n",
    "def pattern_blinker():\n",
    "    return [(0,0),(1,0),(2,0)]\n",
    "\n",
    "def pattern_toad():\n",
    "    return [(1,0),(2,0),(3,0),(0,1),(1,1),(2,1)]\n",
    "\n",
    "PATTERNS = [\n",
    "    (\"Glider\", pattern_glider),\n",
    "    (\"LWSS\", pattern_lwss),\n",
    "    (\"Pulsar\", pattern_pulsar),\n",
    "    (\"GosperGun\", pattern_gosper_glider_gun),\n",
    "    (\"Blinker\", pattern_blinker),\n",
    "    (\"Toad\", pattern_toad),\n",
    "]\n",
    "\n",
    "def place_pattern(state: np.ndarray, pattern_pts, top_left: Tuple[int,int]):\n",
    "    ox, oy = top_left\n",
    "    for (px, py) in pattern_pts:\n",
    "        x, y = ox + px, oy + py\n",
    "        if 0 <= x < NCX and 0 <= y < NCY:\n",
    "            state[x, y] = 1\n",
    "\n",
    "# -----------------------------\n",
    "# Dibujo\n",
    "# -----------------------------\n",
    "def draw_grid(surface):\n",
    "    # (opcional: para rejilla)\n",
    "    for x in range(NCX):\n",
    "        pygame.draw.line(surface, GRID_COLOR, (x*dimCW, 0), (x*dimCW, HEIGHT), 1)\n",
    "    for y in range(NCY):\n",
    "        pygame.draw.line(surface, GRID_COLOR, (0, y*dimCH), (WIDTH, y*dimCH), 1)\n",
    "\n",
    "def draw_cells(surface, state):\n",
    "    # Polígono por celda (relleno si viva)\n",
    "    for x in range(NCX):\n",
    "        for y in range(NCY):\n",
    "            rect = pygame.Rect(x*dimCW, y*dimCH, dimCW, dimCH)\n",
    "            if state[x, y]:\n",
    "                pygame.draw.rect(surface, ALIVE_COLOR, rect)\n",
    "            else:\n",
    "                # borde fino opcional para muertas\n",
    "                pygame.draw.rect(surface, GRID_COLOR, rect, 1)\n",
    "\n",
    "def draw_hud(surface):\n",
    "    lines = [\n",
    "        f\"Regla: {rule_name} [{rule_string}]  |  Toroidal: {'ON' if toroidal else 'OFF'}\",\n",
    "        \"ESPACIO: Pausa/Reanuda   N: un paso   C: limpiar   R: aleatorizar   T: toroidal\",\n",
    "        \"F: cambiar regla   +/-: densidad aleatoria   1..6: insertar patrón bajo el mouse\",\n",
    "        f\"Densidad R: {random_density:.2f}   Celdas: {NCX}x{NCY}   (ESC para salir)\"\n",
    "    ]\n",
    "    y = 5\n",
    "    for txt in lines:\n",
    "        surf = font.render(txt, True, (200, 220, 255))\n",
    "        surface.blit(surf, (8, y))\n",
    "        y += 18\n",
    "\n",
    "# -----------------------------\n",
    "# Lógica principal\n",
    "# -----------------------------\n",
    "last_step_time = 0.0\n",
    "\n",
    "def randomize(state: np.ndarray, p: float):\n",
    "    state[:] = (np.random.rand(NCX, NCY) < p).astype(np.uint8)\n",
    "\n",
    "def toggle_cell_at_mouse(state: np.ndarray, button: int):\n",
    "    mx, my = pygame.mouse.get_pos()\n",
    "    cx, cy = int(mx // dimCW), int(my // dimCH)\n",
    "    if 0 <= cx < NCX and 0 <= cy < NCY:\n",
    "        if button == 1:      # izq: poner viva\n",
    "            state[cx, cy] = 1\n",
    "        elif button == 3:    # der: poner muerta\n",
    "            state[cx, cy] = 0\n",
    "\n",
    "def insert_pattern_under_mouse(idx: int):\n",
    "    mx, my = pygame.mouse.get_pos()\n",
    "    cx, cy = int(mx // dimCW), int(my // dimCH)\n",
    "    name, fn = PATTERNS[idx]\n",
    "    place_pattern(gameState, fn(), (cx, cy))\n",
    "\n",
    "# -----------------------------\n",
    "# Bucle\n",
    "# -----------------------------\n",
    "running = True\n",
    "while running:\n",
    "    clock.tick(FPS)\n",
    "\n",
    "    # Eventos\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            k = event.key\n",
    "            if k == pygame.K_ESCAPE:\n",
    "                running = False\n",
    "            elif k == pygame.K_SPACE:\n",
    "                paused = not paused\n",
    "            elif k == pygame.K_n:          # step\n",
    "                paused = True\n",
    "                # forzar un paso\n",
    "                newState = np.copy(gameState)\n",
    "                for x in range(NCX):\n",
    "                    for y in range(NCY):\n",
    "                        n = count_neighbors(gameState, x, y, toroidal)\n",
    "                        newState[x, y] = apply_rules(gameState[x, y], n)\n",
    "                gameState = newState\n",
    "            elif k == pygame.K_c:          # clear\n",
    "                gameState[:] = 0\n",
    "            elif k == pygame.K_r:          # random\n",
    "                randomize(gameState, random_density)\n",
    "            elif k == pygame.K_t:          # toroidal ON/OFF\n",
    "                toroidal = not toroidal\n",
    "            elif k == pygame.K_f:          # ciclo reglas\n",
    "                rule_index = (rule_index + 1) % len(COMMON_RULES)\n",
    "                rule_name, rule_string = COMMON_RULES[rule_index]\n",
    "                BORN, SURV = parse_rulestring(rule_string)\n",
    "            elif k in (pygame.K_PLUS, pygame.K_KP_PLUS, pygame.K_EQUALS):\n",
    "                random_density = min(0.95, random_density + 0.05)\n",
    "            elif k in (pygame.K_MINUS, pygame.K_KP_MINUS):\n",
    "                random_density = max(0.0, random_density - 0.05)\n",
    "\n",
    "            # Patrones 1..6\n",
    "            elif k in (pygame.K_1, pygame.K_2, pygame.K_3, pygame.K_4, pygame.K_5, pygame.K_6):\n",
    "                idx = k - pygame.K_1\n",
    "                if 0 <= idx < len(PATTERNS):\n",
    "                    insert_pattern_under_mouse(idx)\n",
    "\n",
    "        elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            # Edición con mouse\n",
    "            if event.button in (1, 3):  # izq/der\n",
    "                toggle_cell_at_mouse(gameState, event.button)\n",
    "\n",
    "    # Mantener vivo el “pintado” mientras se arrastra\n",
    "    if pygame.mouse.get_pressed()[0] or pygame.mouse.get_pressed()[2]:\n",
    "        btn = 1 if pygame.mouse.get_pressed()[0] else 3\n",
    "        toggle_cell_at_mouse(gameState, btn)\n",
    "\n",
    "    # Actualización de estado (si no está pausado)\n",
    "    if not paused:\n",
    "        t0 = time.time()\n",
    "        newState = np.copy(gameState)\n",
    "        for x in range(NCX):\n",
    "            for y in range(NCY):\n",
    "                n = count_neighbors(gameState, x, y, toroidal)\n",
    "                newState[x, y] = apply_rules(gameState[x, y], n)\n",
    "        gameState = newState\n",
    "\n",
    "        # retardo opcional para observar evolución\n",
    "        if step_delay > 0:\n",
    "            dt = time.time() - t0\n",
    "            time.sleep(max(0.0, step_delay - dt))\n",
    "\n",
    "    # Dibujo\n",
    "    screen.fill(BG)\n",
    "    draw_cells(screen, gameState)\n",
    "    draw_hud(screen)\n",
    "\n",
    "    # (opcional) draw_grid(screen)  # si querés la rejilla superpuesta\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "pygame.quit()\n",
    "sys.exit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oXcAF__NmgG5"
   },
   "source": [
    "# Bibliografía\n",
    "\n",
    "[Russell, S. & Norvig, P. (2004) _Inteligencia Artificial: Un Enfoque Moderno_. Pearson Educación S.A. (2a Ed.) Madrid, España](https://www.academia.edu/8241613/Inteligencia_Aritificial_Un_Enfoque_Moderno_2da_Edici%C3%B3n_Stuart_J_Russell_y_Peter_Norvig)\n",
    "\n",
    "[Poole, D. & Mackworth, A. (2023) _Artificial Intelligence: Foundations of Computational Agents_. Cambridge University Press (3a Ed.) Vancouver, Canada](https://artint.info/3e/html/ArtInt3e.html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
